# Experiment Design\label{ch5}
In Chapter {ref}`ch4` we described the various circumstances in which we compare the properties of models and of systems.
We encountered such variety that it will come as no surprise to learn that there is no single way to plan experiments.
The techniques and procedures we use depend on circumstances, and we describe procedures that are appropriate to a number of cases.
The list is not exhaustive but it identifies general principles that are valid in a wide variety of experimental circumstances.
Foremost among these is the following.
Whatever the circumstances we encounter, we make sense in our experiment procedures only if we keep clearly in mind this central point-the fundamental requirement in experimenting, whatever else is going on, is to compare the properties of a system with the properties of a model or models.

Assume at the outset that, as the outcome of preliminary investigation, we already know the significant variables.
Some of these are under our control and can serve as input variables.
Others take values determined by the system; they are the output variables.
In the following sections, we assume that the input variables can be separated and individually controlled; otherwise, with everything varying simultaneously, the interpretation of the results is much more difficult.
This unfortunate circumstance is frequently encountered in professional experimenting, but we restrict ourselves here to the case of a fully
controlled experiment.

## To Test An Existing Model\label{sec5_1}
In this section, we are concerned with situations in which a model of some type is already available.
This model can be the simplest of suggestions (whether theoretically derived or empirical), such as `F = kx` or `V = IR`, or it can be derived from some grand, sophisticated theory such as Einstein's theory of general relativity.
Whatever the nature of the model, its properties almost invariably will take the form of a functional relation between two or more variables.
The primary objective is, as always, to compare the properties of the model with those of the system.
Only after we have by experiment, satisfied ourselves that, over some range at least, the properties of the system and of the model overlap, are we entitled to go ahead with the evaluation of the quantity we wish to measure.

Notice that any decision about the appropriateness of the model for the system must be based on the experiment itself.
We are, of course, not going to attempt to decide on such meaningless questions as whether the model or theory is ``true'' or ``false,'' ``correct'' or ``incorrect,'' or whatever.
As we have said so often, all models are imperfect in principle, and we simply need to know if the model is good enough for our purposes at our level of precision.
Only our own experiment can provide the basis for making that decision, and it is one of our major objectives in designing the experiment to ensure that this will be possible.
Once we have checked that our model is good enough, we can proceed to evaluate our unknown quantity, not forgetting that, if our situation changes and increased precision is called for, we must reopen the question of the model's adequacy for our purpose.
As has been described in Section {ref}`sec4_3`, almost invariably the best ways of testing models of physical systems involve a graphical approach.
In principle we wish to draw a graph of the model's behavior and to superimpose on it our observations of the behavior of the system.
To do this in a simple form, however, there are some requirements.

First, because a graph (as we are considering it) is a two-dimensional diagram, we must limit ourselves initially to two variables.
In many cases, this requirement is automatically satisfied, as it has been in all the preceding examples.
In others, however, the output variable is a function of two (or more) independent input variables.
We cannot plot three variables as coordinates on a two-dimensional piece of graph paper (although three-dimensional diagrams can easily be generated by computers and are frequently seen in the scientific literature).
Consequently, for our purposes, it is necessary to simplify the experiment by holding one of the input variables constant while studying the dependence of the output variable on the other.
We can then alter the first variable to a second fixed value and repeat the process.
By a succession of such measurements, we can build up a relatively complete picture of the behavior of the system.
Notice that the success of the process depends on the primary assumption that it is possible to hold one of the input variables constant, independently of variation in the other.
If such isolation of the input variables is not possible, we have problems; some of the necessary techniques are mentioned in Section {ref}`sec5_2`.

For our present purpose suppose that we have only one input variable, either because only one exists or because we can isolate one by holding the others constant.
The procedure is clear; we must measure the variation of the output variable with the input variable and plot the resulting values for comparison with the corresponding graph for the model.
As was suggested in Section {ref}`sec4_3`, however, it would take a computer to draw even simple nonlinear functions, and the advantages of drawing graphs in straight-line form are so overwhelming that we consider only this approach.

## Straight-Line Form For Equations\label{sec5_2}
\subsection*{Simple Cases}
If the model we are considering contains only linear functions (such as distance traveled at constant velocity as a function of time, or the potential difference across a constant resistor as a function of current), we have no problem; the equation is already in straight-line form.
This is rarely the case, however, and we are almost invariably faced with the necessity of converting the functions found in the model into linear form.
We have already encountered this requirement in Section {ref}`sec4_3`.
There the function was

```math
t=0.4515x^{1/2} \hspace{0.5in} {\textrm (in units of meters and seconds)}
```

\noindent and, clearly, if we wish to represent this equation in the linear form,
```math
\mathrm{vertical variable = slope  \times  horizontal variable + constant}
```
\noindent we must choose
```math
\mathrm{vertical variable = }t
```
```math
\mathrm{horizontal variable = }x^{1/2}
```
```math
\mathrm{slope = }0.4515
```
\noindent and
```math
\mathrm{constant = }0
```

This is a simple case, and it is often less easy to see how an equation can be converted into linear form.
There are no definite rules for doing it.
The best way is to keep clearly in mind the form toward which we wish to work,

```math
\mathrm{vertical variable = slope  \times  horizontal variable + constant}
```

\noindent and juggle the quantities in the original equation around until we have the required form.
Opportunities for practice are found in the problems at the end of this chapter.

Notice that there is no unique answer in this process.
A given equation can sometimes be put in linear form in several different ways.
For example, the equation

```math
t=0.4515x^{1/2}
```

\noindent can be used equally effectively in anyone of the equivalent forms

```math
x^{1/2}=\frac{1}{0.4515}t, \hspace{0.5in} t^2 = 0.2309x, \hspace{0.5in} x-4.905t^2
```

\noindent with appropriate choices for vertical variable, horizontal variable, and slope.
There IS a conventional tendency to plot graphs with the input variable horizontally and the output variable vertically, but there is no real requirement to do so.
We should choose the form of graph that most effectively serves our purpose.

Our purpose should include not only the basic experimental requirements, but also the comfort and convenience of the experimenter.
For this, one should plot variables as simply as possible.
For example, consider an experiment to, determine a coefficient of viscosity by studying the flow of liquid through a pipe.
The appropriate equation (Poiseuille's equation) is

```math
Q = \frac{P\pi a^4}{8\eta\ell}
```

\begin{align}\nonumber
{\textrm where \hspace{0.25in}} & Q = \mathrm{ rate of flow (volume/time)}

\nonumber
& P = \mathrm{ pressure difference across length of pipe}

\nonumber
& a = \mathrm{ pipe radius}

\nonumber
& \ell = \mathrm{ pipe length}

\nonumber
& \eta = \mathrm{ coefficient of viscosity}\nonumber
\end{align}
\noindent In this case the measured variables are `P` and `Q`; `a` and `\ell` have constant measured values.
Our intention to plot the quantities to obtain a value for `\eta`.
One possible choice is to plot `Q` versus `\left(\pi a^4 /8\ell\right)P`.
This seems to suit our purposes because the resulting graph has a slope equal to `1/\eta`, but it is an unwise choice for a number of reasons.
First, it greatly increases the amount of arithmetic required to do the plotting, because each value of `P` must be multiplied by `\pi a^4/8\ell` .
Second, each of the quantities `a` and `\ell` has an attached uncertainty; if this were to be combined each time with the uncertainty in `P`, we would have a falsely enhanced uncertainty for the compound quantity (for example, in the actual experiment a would be measured only once, and its uncertainty should not be combined with that of `P` as if every time we measured `P` another measurement of a were made to combine with it).
 Clearly, in this case the path of wisdom is to plot `Q` versus `P` and to use `\pi a^4 /8\eta\ell` as the slope, thus avoiding all the difficulties just mentioned.
We
are then able to calculate `\eta` from the value for the slope and the measured values of `a` and `\ell` using

```math
\eta = \frac{\pi a^4}{8\ell\times { \textrm slope}}
```

In general, it is best to plot variables that are as simple as possible and to leave most of the arithmetic to be done just once in calculating the answer from the slope.

\subsection*{Use of Compound Variables}
In many cases it may suit our convenience (or else it may be absolutely necessary) to plot the graph using variables that are not single measured quantities but are constructed out of the primary measurements.
Consider, for example, the so-called compound pendulum, a rigid lamina of a certain shape that is allowed to oscillate under gravity about an axis perpendicular to the plane of the lamina, as shown in Figure {ref}`Fig5_1`(a).
\newpage
```{figure} figures/ch5/Fig5_1a.jpg
:The compound pendulum and its variation of oscillation period with h.
:Fig5_1
```
\newpage
\noindent The normal model of its oscillation (for small angles of oscillation) gives the period of oscillation. `T`, as

```math
T = 2\pi\sqrt{\frac{h^2+k^2}{gh}}
```

\begin{align}\nonumber
{\textrm where \hspace{0.1in}} & T = \mathrm{ period of oscillation (output variable)}

\nonumber
& h = \mathrm{ distance from center of mass to point of support (input variable)}

\nonumber
& g = \mathrm{ gravitational  acceleration  (constant  and  unknown)}

\nonumber
& k = \mathrm{ radius  of  gyration  about  center  of mass  (constant  and  unknown)}\nonumber
\end{align}

\noindent Straight-line forms of this equation are not immediately obvious, but it is clearly impossible to place it in the required linear form if we choose the horizontal and vertical variables to be functions of `h` and `T` singly.
Conversion into linear form by using compound variables is possible.
Squaring both
sides of the equation, we obtain

```math
T^2 = \frac{4\pi^2\left(h^2+k^2\right)}{gh}
```

\noindent Therefore,

```math
T^2h = \frac{4\pi^2\left(h^2+k^2\right)}{g}
```

\noindent and

```math
h^2 =\frac{g}{4\pi^2}T^2h - k^2
```

\noindent which is now in linear form with
\begin{align}\nonumber
    {\textrm vertical  variable  } &= h^2

\nonumber
    {\textrm horizontal  variable  } &= T^2h

\nonumber
    {\textrm slope  } &= \frac{g}{4\pi^2}

\nonumber
    {\textrm intercept  } &= -k^2\nonumber
\end{align}

\noindent Notice how in this case plotting in straight-line form is possible only by using compound variables.

This example is worth studying because it illustrates very clearly the superiority of linear analysis over other methods.
A commonly encountered approach to this experiment uses the graph of `T` versus `h`, which is shown in Figure {ref}`Fig5_1`(b).
It turns out that the graph directly supplies only the value of `k`, which can be obtained from the lengths of the intercepts `AB` and `CD`.
If `g` is required, it must be obtained by calculation from the value of `k`.
The advantages of the linear form of analysis are clear.
First, the `T` versus `h` graph gives no basis for comparing the system with the model, unless one uses a computer to draw the graph of the function `T(h)`.
Second, no reliable estimate of the uncertainty of the final answer can be obtained from this graph, whereas the overall uncertainty can readily be obtained from the linear graph.
Third, the use of an intercept at such a low angle, as illustrated in Figure {ref}`Fig5_1`(b).
is unreliable, because small changes in placing the lines can cause large changes in the length of the intercepted portion; a linear form, on the other hand, enables us to determine the slope of the graph reliably.
Fourth, by using the intercept method the answer is determined solely by a few points in the vicinity of the intercepts, and we obtain no benefit from all the other points.
When drawing a straight line, however, all the points can contribute to the choice of the line.
Last, the linear graph gives `g` and `k` from almost independent measurements on the graph, whereas with the other method any inaccuracy in the value of `k` is propagated automatically into the value of `g`.
The use of compound variables can also be convenient when there are two or more separate input variables.
In such cases, even if the use of compound variables is not absolutely necessary for linear plotting (as it was for the compound pendulum), they often provide the neatest and most effective way of plotting graphs.\index{compound variables, plotting} It was mentioned earlier that, if a system involves two independent input variables, we can study the variation of the output variable with either input variable in isolation, while holding the other input variable at a number of discrete levels.
For example, if we wish to measure the specific heat of a fluid, `C`, by continuous-flow calorimetry, we can allow it to flow at a certain mass flow rate, `m`, through an electrically heated tube in which the rate of heat generation is `Q` per unit time.
The equation for the resulting heat balance (neglecting losses, etc.) is

```math
Q=mC\Delta T
```

where `\Delta T` is the difference in temperature between the input and output ends of the tube.
Clearly, both `Q` and `m` are separately controllable, and we can perform our experiment by studying the variation of `\Delta T` with `m`, holding `Q` at various fixed levels, or we can study the variation of `\Delta T` with `Q` holding `m` at various fixed levels.
We would then be able to plot either `\Delta T` versus `1/m`, in which case the various slopes would have values `Q/C`, or else `\Delta T` versus `Q`, which would give the various slopes as `Cm`.
Neither possibility by itself provides a complete description of the behavior of the system.
Another possibility exists.
If we treat the product `m\Delta T` as \textit{one} variable and plot it against `Q`, we obtain a single graph that summarizes all the information about the system by incorporating both input variables simultaneously, whether we did or did not control the values of `m`.
The slope would simply have the value `C`, and we would have a neat way of testing the model and obtaining our unknown in one simple step.

Such use of compound variables is common, and, as before, the choice of combination for the variables and the mode of plotting can be made to suit both the convenience of the experimenter and the requirements of the experiment.
If any difficulty in interpreting observations appears when they are plotted by using compound variables (unexpected scatter, perhaps, or some systematic deviation from linearity), we can always obtain extra information about the system by reverting to a plot of the pairs of variables individually rather than in combination.
By isolating the effects of the separate input variables we can usually identify the cause of any difficulty.

\subsection*{Logarithmic Plotting}
It is frequently desirable and sometimes absolutely necessary to plot variables in logarithmic form.
For example, many physical processes involve exponential functions of the form

```math
y=ae^{bx}
```

\noindent where `y` and `x` are measured variables and `a` and `b` are constants whose values are to be obtained from the experiment.
The equation can be put in linear form by taking logs of both sides to the base `e`.
We obtain

```math
\log_e y = \log_e a + bx
```

Thus, if we plot `\log_e y` vertically and `x` horizontally (known as a ``semi-log plot''), the model gives us a straight line.
The slope gives `a` value for `b`, and the intercept gives the value of `\log_e a`.
Notice that, if logs are taken to the base 10 instead of `e`, only the intercept is affected, and this can be convenient if we are interested in the slope only.
The use of such logarithmic plotting is common because of the frequent occurrence of exponential functions in the models of physical and chemical processes.
In addition, logarithmic plotting is used even for simple algebraic functions.
Consider, for example, the function

```math
y=x^2
```

\noindent Taking logs of both sides, either base 10 or base `e`, we obtain

```math
\log y = 2 \log x
```

\noindent This equation is linear with

\begin{align}\nonumber
{\textrm vertical  variable } &= \log y

\nonumber
{\textrm horizontal  variable } &= \log x

\nonumber
{\textrm slope } &= 2\nonumber
\end{align}

\noindent Thus, functional dependence like a simple square can be tested by using such logarithmic plotting (known as a ``log-log plot'').

But what is the advantage of this type of graph over a plot, as we have been recommending all along, of `y` versus `x^2`? One obvious answer is that it allows us to plot on one piece of paper of reasonable dimensions variations that are too extensive for traditional plotting.
A range of one power of 10 in our observations can be conveniently plotted on simple graph paper, a range extending over a factor of 100 is difficult, and a factor of 1000 makes satisfactory plotting impossible.
For these very large excursions of the variables only logarithmic plotting allows realistic representation of the results.

A second advantage of logarithmic plotting concerns the power of the function.
If the system is behaving in such a way that the function

```math
y=x^{1.8}
```

\noindent would be a better model than `y = x^2` , that fact would probably elude us if we plotted `y` versus `x^2`.
We would simply obtain a set of points that deviate from a straight line, and the source of the discrepancy would not be immediately obvious.
The log-log plot, on the other hand, would still give us a straight line, and this would tell us that some function involving a power was still a good model.
The slope of the line would not be 2, of course, and the improved value of the exponent, 1.8, would be available from the slope of the log-log graph.
In.
Chapter {ref}`ch6`, we consider further the uses of log-log plotting for the construction of empirical models involving such powers.
It suffices for the moment to note that, at the stage of designing an experiment, the possibility of semi-log or log-log plotting should be kept in mind if either the type of function or the range of variables suggests that either is appropriate.

## Planning and Experiments\label{sec5_3}
We now list the actual, practical steps by which we prepare to do the experiment.
These may seem tedious to those whose ambition is to get on with the experiment as quickly as possible and worry later about what to do with the results.
Indeed, for many of the simple experiments commonly encountered in teaching laboratories, the painstaking care that we are about to recommend may seem pointless and pedantic.
But remember that the simple experiments in teaching laboratories are merely simulations in suitably simplified forms of the much more complicated and important situations that will be encountered later in real systems.
If, in an introductory physics laboratory, we forget to measure the wire diameter while doing an elasticity experiment, it is probably not going to matter too much.
We can return to the laboratory later and recover the offending measurement; even if we do not, the world will not come to an end.
But if ten years later we plan some space-based astronomy with a very expensive telescope in a spacecraft and we notice only when our experiment is in orbit that we have omitted to test the optics properly, the consequences can be very serious.
Acquire as early as possible the habit of meticulous and painstaking planning of experiments even if, for the moment, such planning may sometimes seem over-meticulous and superfluous.

The planning steps are as follows:
1. Identify the system and the model.
2. Choose the variables.
3. Rectify the equation.
4. Choose the ranges for the variables.
5. Consider the overall precision of the experiment.

\subsection*{Identify the System and the Model}
This step may seem somewhat trivial, but it is sometimes surprisingly difficult to identify what, exactly, is the system we are studying.
Obviously, we cannot do an experiment if we are not clear, right at the beginning, about the topic of the experiment.
The actual phenomenon under study is often surrounded by so much measuring apparatus that we can lose sight of the fundamentals.
If we encounter difficulty in answering the question-What, exactly, is the system under study?
-- we can try looking for the answer to the equivalent question -- what is it whose properties are described by the model?

Similarly, identify clearly the model and the limitations contained within it.
In the falling-ball experiment, for example, are we going to worry about air resistance or not?
If we decide to ignore the presence of the surrounding air in the system, we are not being irresponsible-we are merely defining one aspect of the model that will be used.
Whether this is a good decision will be made clear later by the experiment itself.
If the behavior of the system turns out to be in correspondence with the behavior of the model at the level of precision we use, we can be satisfied that there would have been no point in wasting time on small effects.
If we make a poor choice, the results of the experiment will very quickly
inform us of the necessity of reconsidering the matter.
So, at the outset, we decide on the limits of the system and the model, and we proceed to test the situation.

\subsection*{Choose the Variables}
Usually, one quantity in the experiment is an obvious choice for an output variable.
If there is only one input variable, there is no problem.
If there are several input variables, try to identify one as the chief independent variable and vary the others in discrete steps.

\subsection*{Rectify the Equation}
The equation representing the behavior of the model must now be put into straight-line form, as described in Section {ref}`sec5_2`.
As we have already mentioned, there is no unique, correct choice for the straight-line form.
Choose a form that suits the purposes conveniently and effectively.
For example, if the equation contains some unknown quantity the value of which is to be determined by the experiment, it is probably best to use a form for the straight line that puts the unknown into the slope.
It is possible to determine unknown quantities from intercepts, but because intercepts can frequently be subject to errors arising from instrument defects or other systematic errors, it is usually preferable to obtain unknowns from slopes.
If the equation contains two unknowns, it is probably best to find a form that enables us to obtain one unknown from the slope and the other from an intercept.

\subsection*{Choose the Ranges for the Variables}
Before starting the actual measurements, we should make decisions about the ranges over which we hope to make them.
It is usually best to plan on a range for the input variable of at least a factor of 10.
More is better, and less can often give an unsatisfactory basis for comparing the behavior of systems and models.
Obviously, we cannot choose directly the range of the output variables; the system itself will tell us these values, but we must still be careful.
There may be instrument limits beyond which damage can occur -- elastic limits, overheating of precision resistors, overloading of meters and other instruments, and the like.
Carefully made trial measurements will allow us to determine the range of the input variables that will avoid overloading any part of the system.
This is the time to consider carefully all aspects of instrument ratings, which can be particularly significant for electrical apparatus.
For example, does the resistance box have marked on it the maximum current for each range?
If so, we incorporate that limit into the choice of range for the variables.
If the limits for some pieces of equipment are not marked on the equipment itself, we must find the values in the manufacturer's catalog.
In all cases, we must ensure that limits are identified and observed.
It is too late when the smell of overheated insulation or a vertical column of blue smoke above a meter alerts us to the frailties of physical apparatus and the expense of replacement.

\subsection*{Consider the Overall Precision of the Experiment}
We should not start an experiment until we have a general idea of the precision we hope to attain in the overall result.
This is not to say that we can guarantee a final level of precision, but we should have a target figure to serve as a guide for our choice of measurement methods.
For example, the request -- Measure the acceleration of gravity using a pendulum -- is by itself virtually meaningless.
In response to this request, we could spend ten minutes with crude apparatus and obtain a result with a precision of 10\
We can obtain a realistic impression of the expectation only from some requests such as: Measure `g` using a simple pendulum with a final uncertainty around 2\
The figure 2\

Whether or not it is specified in the requirement we have been given, we should have such a target in mind for every experiment we do, for only then do we have the basis for realistic design of the experiment.
It will give us the opportunity to ensure that all our measurements are of sufficient precision to contribute usefully to the final result and that we do not waste time and effort making some measurement with precision far in excess of that required.

To see how such a design could be carried out, we return to the example of the pendulum and the hoped-for value of 2\
We know that the result for `g`, although it will be obtained graphically, in essence, involves measurements of `\ell` and `T` (in the form `^T2`). If the uncertainty in any measurement of either `\ell` or `T^2` is in excess of 2\
Suppose, as a first guess, we elect to restrict the uncertainties in each of `\ell` and `T^2` to fall below 1\
What are the implications for the measurements of `\ell` and `T`? The first step must be to make trial measurements
to assess the absolute uncertainty with which we can make measurements of `\ell` and `T`.
Once we have determined these uncertainties, we can find the limits on the ranges of the `\ell` and `T` measurements that allow the precision to be acceptable.
Assume that with the apparatus available we are fairly sure that we can measure lengths with an absolute uncertainty of `\pm 1` mm.
What is the measured length at which this uncertainty corresponds to precision of 1\

```math
\frac{0.1}{\ell} = 0.01 \hspace{1in} (\ell \textrm{in  cm})
```

\noindent then the value of `\ell` is given by

```math
\ell = 10 \textrm{cm}
```

\noindent Thus, so long as the measured lengths are greater than 10 cm, the contribution to the overall uncertainty from `\ell` is within the acceptable range, and we have identified one limit on the acceptable range of `\ell`.

What are the corresponding implications for the measurements of `T`? If we are going to ascribe a precision of 1\
The period of oscillation is determined by timing a specified number of oscillations with some kind of timer or stopwatch, and the choice of measuring procedure is determined by the basic uncertainty in that timing device .
Suppose we are using a stopwatch that (as we can determine by actually trying the measurement) allows us to measure the time for a number of oscillations to within `\pm 0.2` s.
Notice that this figure of 0.2 s must be the overall uncertainty in the whole timing process, not just the uncertainty with which we can read the stopwatch once it has stopped.
We must include the complete sequence of judging the pendulum's position, pressing the button, and so on.
The resulting uncertainty in the overall timing process may substantially exceed the simple uncertainty in reading the scale, and we shall probably have to determine it for our particular circumstances by trying the measurement several times.
In any case, if we have an overall uncertainty in the timing measurement of `\pm 0.2` s, we can calculate the relative uncertainty of any timed interval, `t`, as `0.2/t`.
This is the quantity that we wish to restrict to values below 0.5\

```math
\frac{0.2}{t} = 0.005
```

\noindent The limiting value of `t` is therefore given by

```math
t = \frac{0.2}{0.005} = 40 \textrm{s}
```

\noindent Thus, provided we choose the number of pendulum oscillations so that we are never measuring times less than 40 sec, we have a good basis for hoping that our measurements of oscillation time will all contribute effectively to an overall determination of g within 2\
We cannot guarantee that such an experimental plan will result in a value for `g` with an uncertainty no greater than 2\
But at least we can avoid making measurements that stand no chance at all of contributing usefully to the overall result.

At this stage, we must consider whether each measurement is going to be considered in terms of uncertainty derived from personal estimate or whether random fluctuation is large enough to require the use of statistical methods .
If the latter, some trial measurements will allow us to make a preliminary estimate of the variance and so enable us to choose the sample size that will be required if we wish to attain a certain level of precision.
At this point, we must recall the warnings about inaccuracy in small samples that were given in Section {ref}`sec3_11`.
In addition, however, we should remember that attempts to improve precision by increasing the sample size can be unrewarding.
The expression for the standard deviation of the mean involves IN, so that if a trial sample of 10 measurements suggests the desirability of, say, a tenfold increase in precision, the sample size would have to be increased by a factor of 100.
A sample size of 1000 may not be practicable, and we would have to seek some other route to improve precision.

Whether the measurements are statistical in nature or whether they have simple, estimated uncertainty, it should be possible at this stage to decide if each measurement in the experiment can be satisfactorily made.
If it appears that some measurement is restricted to an uncertainty in excess of the design aspirations, we must either obtain a more precise method of measuring that particular quantity, or if that is not possible, we must acknowledge that our former target for the overall uncertainty of the experiment was unrealizable with the apparatus available and that revision of the target value is necessary.
Also, by assessing the contribution of each quantity in the experiment to the overall uncertainty, we can identify any measurement that makes a dominating contribution to the final result, either because of low intrinsic precision or because of the way in which it enters into the calculation (e.g ., some quantity raised to a high power, or a quantity that has to be obtained as the difference between two measured values).
Once identified, these measurements can be given special attention so that their uncertainty can be kept under control as much as possible.

All the detail described in this section may seem to constitute an unnecessarily exacting approach to a small, simple experiment, but it is wise to recall again that we are practicing for much bigger, more important experiments in which the consequences of failure to plan properly can be serious and expensive.

\subsection*{Construction of Measurement Program}
After choosing the variables, ranges, and precision of measurement, it is best to conclude the design of the experiment by constructing a complete and explicit measurement program.
This will normally take the form of a table that includes all the quantities to be measured in the experiment and that also provides space for any computations required for drawing the graphs.
A completed measurement program allows the experimenter to concentrate during the course of the experiment on the actual conduct of the experiment.
While one is manipulating apparatus and making measurements, there is usually enough to be done without the continuous necessity of deciding what to do next.
The measurement program also helps to guard against the accidental omission of some significant measurement that could be overlooked as a consequence of the pressure of actual experimenting.

The complete process of experiment design is illustrated in the description of a sample experiment in Appendix {ref}`A4`.

As we have remarked frequently, all this planning may seem like an unnecessary amount of fuss for a simple experiment.
These recommendations, however, represent nothing more than the basic minimum of preparation for any serious experimenting, and no opportunity should be lost for the early formation of careful habits of experiment design and planning.
It is important to avoid the temptation to rush ahead with the experiment, leaving until later the task of deciding what to do with the results; it is much more beneficial to acquire the habit of setting aside the time to design and plan an experiment properly before starting the actual measurements.

## Experiment Design When There Is No Existing Model\label{sec5_4}
The problem of designing an experiment when there is no model appears when, for example, we are making observations on some phenomenon that is so new that a theoretical model has not yet been constructed, or else on some system that is so complicated (e,g., a complex engineering system or some aspect of national economics) that it will probably never be possible to construct a satisfactory theoretical model for it.
If we do not have an existing model to test, our objective in doing experiments on the system can take several forms.
We may be motivated by simple curiosity or by a practical need for information about the system.
At a higher level, we may be interested in the possibilities of model building.
We may be seeking guidance for the construction of a theoretical model, or if this is too difficult, we may wish to obtain measurements to serve as a basis for a purely empirical model of the system.
As was mentioned in Chapter {ref}`ch4`, even in the absence of detailed, theoretical understanding, empirical models are extremely useful.
They can be helpful in systematizing our thoughts about a complex system, and they are usually essential for such mathematical calculations on the system as interpolation, extrapolation, forecasting, and so on.

Whatever the motivation, we need a function or graph that provides a good enough fit to the observations.
The methods of finding suitable functions are described in Chapter {ref}`ch6`.
We restrict ourselves for the moment to the question of designing the experiment.
In the absence of an existing model, experiment design can be relatively straightforward, especially if we can isolate the input variables so that we can vary one while holding the others at fixed values.
Experiment design can consist simply of measuring the output variable over suitable ranges of the input variables to build up as complete a picture of the behavior of the system as possible.
If we cannot isolate the input variables, we have problems, and this case is considered in Section {ref}`sec5_7`.

Even if there is no existing theory for a phenomenon, it is wise to accept any available hints about functions that might be appropriate to our system and to test these possibilities against the system's behavior.
One way of obtaining such suggestions is discussed in the next section.

## Dimensional Analysis\label{sec5_5}
Even without a complete theory of a physical phenomenon, it is still possible to obtain useful guidance for the performance of an experiment by dimensional analysis.
The dimensions of a physical (mechanical) quantity are its expression in terms of the elementary quantities of mass, length, and time, denoted by `M`, `L`, and `T`.
Thus, velocity has dimensions `LT^{-1}`, acceleration `LT^{-2}`, density` ML^{-3}`, force (equals mass `\times` acceleration) `MLT^{-2}`, work (equals force `\times` distance) `ML^2T^{-2}`, and so on.

The principle used in dimensional analysis is based on the requirement that the overall dimensions on the two sides of an equation must match.
Thus, if `g` is known to be related to the length and period of a pendulum, it is obvious that the only way by which the `LT^{-2}` of the acceleration on the left side can be balanced on the other side is to incorporate the length to the first power (to give the `L`) and the period squared (to provide `T^{-2}`). We can thus say immediately that, whatever the final, theoretical form for the equation, it must have the structure

```math
g= \left(\textrm{dimensionless constant }\right)\times\left(\frac{\textrm{length}}{\textrm{period}^2}\right)
```

The process can give no information about dimensionless quantities (pure numbers such as `\pi`, etc.), and so we must always include their possible presence in equations obtained by dimensional analysis.

The general method is as follows.
Consider a quantity z that is assumed
to be a function of variables `x`, `y`, and so on.
Write the relation in the form

```math
z\propto x^ay^b
```

where `a` and `b` represent numerical powers, initially unknown, to which `x` and `y` may have to be raised.
Then write down the dimensions of the right-hand side in terms of the dimensions of x and y and of the powers `a` and `b`.
Second, set down the condition that the total power of the dimension `M` on the right-hand side must be the same as that known for `z`.
Do this also for `L` and `T`, obtaining thereby three simultaneous equations that enable us to calculate values for `a`, `b`, and so on.

For example, consider the velocity `v` of transverse waves on a string.
We might guess that this velocity is determined by the tension `T` in the string (not to be confused with the `T` that appears as the dimensional symbol for time) and the mass per unit length `m`.
Let us write

```math
v\propto T^am^b
```

\noindent The appropriate dimensions are,

\begin{align}\nonumber
{\textrm of } v \hspace{1in} & LT^{-1}

\nonumber


\nonumber
{\textrm of } T \textrm{( force)}\hspace{1in} & MLT^{-2}

\nonumber


\nonumber
{\textrm of } m\textrm{( mass per unit length)}\hspace{1in} & ML^{-1}\nonumber
\end{align}

\noindent Therefore,

\begin{align}\nonumber
LT^{-1} &= \left(MLT^{-2}\right)^a   \left(ML^{-1}\right)^b

\nonumber


\nonumber
&= M^{a+b}\times L^{a-b} \times T^{-2a}\nonumber
\end{align}

\noindent Thus, by comparing in turn the powers of `M`, `L`, and `T` on the two sides of the equation, we obtain

\begin{align}\nonumber
{\textrm for } M \hspace{1in} & 0 = a + b

\nonumber


\nonumber
{\textrm for } L \hspace{1in} & 1 = a - b

\nonumber


\nonumber
{\textrm for } T \hspace{1in} & -1 = -2a\nonumber
\end{align}

\noindent of which the solutions are obviously

```math
a=\frac{1}{2} \hspace{0.5in} {\textrm and} \hspace{0.5in} b = -\frac{1}{2}
```

\noindent We obtain finally

```math
v =  \left(\textrm{dimensionless constant }\right)\times\sqrt{\frac{T}{m}}
```

Such a procedure is very valuable, for even in the absence of a detailed, fundamental theory, it provides a prediction regarding the behavior of the system.
This can be a starting point for experimental investigation.
If the experiment shows consistency between the system's behavior and the model produced by dimensional analysis, we have confirmation of the validity of our original guess regarding variables.
If the experiment shows a discrepancy, we must look again at our primary suppositions about the quantities involved in the experiment.
Notice that in the foregoing example we obtained three equations for only two unknowns.
The situation, therefore, was really over-determined, and we were fortunate that the equations containing `a` and `b` were consistent.
Had that not been the case, we would have known immediately that our guess regarding the constituents of `v` was wrong.

Powerful as this method is, difficulties obviously arise when the quantity under discussion is a function of more than three variables.
We then have more than three unknown powers but only three equations from which to determine them.
A unique solution is not possible, but a partial solution may be found in terms of combinations of variables.

For example, consider the flow rate `Q` of fluid of viscosity coefficient `\eta` through a tube of radius `r` and length `\ell` under a pressure difference `P`.
All these quantities are clearly significant in determining the flow rate, and so we may suggest a relation

```math
Q\propto P^a\ell^b\eta^cr^d
```

The dimensions of the quantities are as follows:

\begin{align}\nonumber
Q & \textrm{ (volume per unit time) }  & L^3T^{-1}

\nonumber


\nonumber
P & \textrm{ (force per unit area) }  & MLT^{-2}\times L^{-2}=ML^{-1}T^{-2}

\nonumber


\nonumber
\ell & \textrm{ (tube length) }  & L

\nonumber


\nonumber
\eta & \textrm{ (viscosity coefficient:} & 

\nonumber
 & \textrm{ force per unit area} & 

\nonumber
 & \textrm{ per unit velocity gradient) }  & (MLT^{-2})(L^{-2})(LT^{-1}\times L^{-1})=ML^{-1}T^{-1}

\nonumber


\nonumber
r & \textrm{ (tube radius) }  & L\nonumber
\end{align}

\noindent Therefore,

```math
L^3T^{-1} = \left(ML^{-1}T^{-2}\right)^a L^b \left(ML^{-1}T^{-1}\right)^c L^d
```

\noindent Comparing powers of

\begin{align}\nonumber
 M \hspace{1in} & 0 = a + c

\nonumber


\nonumber
L \hspace{1in} & 3 = -a + b - c + d

\nonumber


\nonumber
T \hspace{1in} & -1 = 2a - c\nonumber
\end{align}

Here we have four unknowns and only three equations, so that in general a complete solution is not possible.
We can obtain part of it, however, for it is obvious that the `M` and `T` equations give us

\begin{align}\nonumber
 a &= 1

\nonumber


\nonumber
c & -1\nonumber
\end{align}

\noindent The equation for `Q` must therefore contain the term `P/\eta`.
The remaining part of the solution can be written only as

```math
b+d = 3
```

\noindent If we write this

```math
d=3-b
```

\noindent we can see that `Q` must contain the product `r^3/r^b`.
It also contains `\ell^b`, so that we can write

```math
Q\propto \frac{P}{\eta}\times r^3\times \left(\frac{\ell}{r}\right)^b
```

\noindent Because it is inconceivable that `Q` should increase with `\ell`, if all other quantities are kept constant, it is obvious that `b` must have a negative value, and we can invert the `\ell/r` term to obtain, finally,

```math
Q\propto \frac{P}{\eta}\times r^3\times \left(\frac{r}{\ell}\right)^b
```

The quantity `b` remains unknown, and this is as far as dimensional analysis can take us toward the complete solution.
Even this partial solution, however, could serve as a guide to experimenting in a situation in which no fundamental theory existed.
Dimensional analysis can be extended to cover thermal and electrical quantities, but in those cases ambiguities arise and they require special consideration.
The appropriate discussion can be found in the standard texts on heat and electricity or in the specialized texts on dimensional analysis.

## Difference-Type Measurements\label{sec5_6}
In all the preceding sections we have assumed that there was a clear and definite relationship between the input and output variables, and that the input variables themselves were readily identifiable and relatively well controlled.
We do, however, encounter circumstances in which we are not so fortunate.
Perhaps our input variables cannot be clearly isolated, so that, with everything varying at once, it is difficult to identify the effect of each on the output of the system.
Or perhaps the system is so complex and subject to so many variable factors that we find it hard to judge whether the effect in which we are interested even exists.
Many experimental techniques, mostly of a statistical nature, have been devised for use in such circumstances.
Descriptions of these can be found in the texts on statistics listed in the Bibliography.
For our present purpose, we restrict ourselves to a brief description of the problems appearing at the various levels of complexity and uncertainty.

\subsection*{Difference-Type Experimenting in the Physical Sciences}
Suppose we wish to study some relatively small effect, such as the extension of a hard steel wire under load.
Not only is the effect small, but it also is subject to a number of perturbing factors-for example, temperature.
If we simply measure, therefore, the extension of a particular wire under a certain load without ensuring temperature stability, we cannot be certain that the extension we measure can be ascribed uniquely to the influence in which we are interested, namely, load.
Not only that but if in addition we are actually unable to control the temperature, we shall never be able to be sure about the effect of load on the wire.
The solution is a \textbf{null-effect} measurement.
We study two identical specimens simultaneously, one loaded, the other not, and we measure the \textit{difference} in length between the two specimens.
The wire under load shows the behavior of the system as it is tested, while the unloaded wire provides the null effect-that is, the behavior of the system in the \textit{absence} of the load.
We can then hope to ascribe the measured difference in length to the influence in which we are interested, the load, and the perturbing influences that affect the two wires equally are prevented from introducing errors into the measurements.
We must obviously try to ensure that, as far as possible, the two specimens be identical, be subject to exactly the same influences, such as temperature, and differ in only the one respect-load.

Fortunately, such correspondence is not too hard to achieve if we are talking about steel wires.
We can come close to making the situation of the two wires identical by mounting them close together (to minimize temperature differences between them) and by taking other similar precautions.
And because we wish the basic properties of the two specimens to be as close to identical as possible, we can simply take one length of wire and cut it in two, making one piece the specimen to be loaded and the other the comparison specimen that will indicate the null effect.
Our ability to cut the specimen in half allows us conveniently to perform a great variety of difference types of measurements and to obtain high precision in the detection of small effects that would otherwise be hopelessly obscured by perturbing factors.
Such experimenting is common and is encountered over the whole range of physical phenomena.

It is always good experimental practice to check the performance of an experimental system ill the absence of the influence we are studying as well as in its presence.
Sometimes the results are surprising, and we do well to take the advice of Wilson (see the Bibliography) and reflect on the statement: It has been conclusively proved by numerous tests that the beating of drums and gongs during a solar eclipse causes the sun's brightness to return.

\subsection*{Difference-Type Experimenting in the Biological Sciences}
In illustrating null-effect measurements using the extension of a loaded steel wire, we have encountered one very convenient aspect.
To guarantee the similarity of the experimental specimen and the comparison specimen, we cut the basic specimen in half.
In the case of steel wires and other similar materials, that presents no problem, but other systems are not so cooperative.

Suppose we wished to measure the effectiveness of a new drug for a particular type of illness.
It would clearly be of little value if we did nothing other than simply administer the drug to a patient suffering from the disease and watch for improvement.
There are far too many variable and perturbing factors for us to ascribe confidently any change in the patient's condition to the drug.
If we wish to isolate the effect of the drug alone.
We should clearly try to design some sort of difference-type experiment in which we observe the null effect as well as the influence of the drug.
Such a requirement raises obvious difficulties not encountered when experimenting on steel wires.
The reluctance of most human specimens to be cut in half makes it impossible to create a genuine null-effect specimen.
We could use a second person as a null-effect specimen, but we would immediately encounter all the variability of response that we had sought to evade by using identical specimens.

Faced with the inevitability of biological variability, our only recourse is to compensate with increased numbers.
We abandon attempts to experiment on single specimens and construct an \textit{experimental group}, which we expose to the influence under study, and a \textit{control group}.
The control group is constructed to be as closely comparable as possible to the experimental group, differing only in that it does not receive the treatment that forms the topic of the research.
It will, we hope, be exposed to all the perturbing influences that affect the experimental group, will respond to them in the same way as that group, and will therefore provide the null-effect measurement.

Many refinements may have to be built into this kind of experimenting, because the effects we seek to measure can often be quite small in comparison with all the perturbing influences.
For example, to diminish subconscious distortion of the results in medical experimenting on human subjects, it is common to offer the members of a control group a simulation of the real material given to the experimental group (a placebo), and to keep both the experimenters and the subjects in ignorance of the allocation of real and simulated material (the so-called double-blind experiment).

Experiment designs involving an experimental group and a carefully matched control group are virtually universal in biological studies, whether we are trying to measure the possible carcinogenicity of some food dye in large numbers of unfortunate mice or the beneficial effects of musical activities on the academic achievement of elementary school students.

## Experimenting With No Control Over Input Variables\label{sec5_7}
Sometimes we have to design a process to study some system over which we have no control at all.
If this is the case, we have no alternative to simple unmanipulative observation of the system, and our task is to design the observational procedure (perhaps we are not justified in calling it an experiment) to optimize our chances of effective comparison between the properties of the system and those of any model we have in mind.
In cases of clear-cut behavior of the system and well-defined models, we may not have too much of a problem.
For example, astronomers may suffer the frustration of inability to influence their subject matter, but their system usually functions in a well-defined manner, often permitting extremely accurate measurement.
In this way it is not too hard to decide that Einstein's theory of general relativity fits the observations on the orbit of the planet Mercury better than does Newton's theory of gravitation.

In other cases, however, the questions we ask may be harder to answer.
For example, has the introduction of a new detail of manufacture altered the quality of a manufactured product?
Even when everything in the manufacturing process is kept as nearly constant as possible, observation shows that the product varies from specimen to specimen.
Does this variance mask the effect in which we are interested?
Without control over our input variables, the study becomes an exercise in, sampling procedures, and a whole field of industrial study exists under the title of ``quality control.'' The literature on statistics and statistical experiment design is extensive; some of the texts listed in the Bibliography provide a starting point.

Even industrial processes, with their inherent fluctuations and their lack of input control, pose problems that are simple in comparison with some of the questions to which we seek answers today.
Does the addition of fluorides to municipal water supplies improve the condition of peoples' teeth, and does it have other, possibly harmful effects?
Do nuclear power stations cause a higher incidence of leukemia in their vicinity?
In seeking the answers, we have almost every problem that can face an experimenter.
There is little or no control over the input variables, there is wide variation in individual response, the response may be of only a probabilistic nature, there may be long delays in observing a response, there is rarely an opportunity to observe a genuine null effect (we do not normally carry out surveys of sufficient sensitivity before the municipality starts to add fluorides or before the nuclear power station is built), and there is commonly a multitude of confusing extraneous factors.
The only thing we can do is to carry out the sampling procedure as carefully as possible.
We must obtain an artificial null-effect measurement by constructing an experimental group as large as possible that is under the influence we are studying and a control group that is exempt from that influence but that in every other respect matches the experimental
group as closely as possible.

The whole point in this kind of experimenting or survey work lies in the skill and care with which the sampling is done.
The effects under study are usually so subtle that, as a consequence of no more than changes in sampling procedure, it is not uncommon for different surveys to provide completely contradictory conclusions.
It is not completely unknown that people with special interests in mind can supply results of surveys to ``prove'' their point, obtaining the result they want by careful control over their sampling procedures.
Many of the issues in which scientific matters have a bearing on public policy have this characteristic of uncontrollable input variables, and we should all become as familiar as possible with the procedures used for sampling and significance testing.
In this way we may be able to judge as accurately as possible the usually conflicting claims of the protagonists.

When faced with problems of such complexity, we must frequently abandon familiar patterns of thought that have been successfully used in other areas.
For example, the word \textit{proof} is legitimately used in many contexts.
We can, for example, prove mathematical results as consequences of mathematical principles.
The word is also used (perhaps less legitimately) with reference to measurements when the uncertainty level permits.
Most reasonable people would accept it as ``proved'' that the sun is more distant from the earth than the moon (although it would be better to say simply that the distance is measured to be greater).
But there are other areas in which we cannot use the word at all.
We have all heard claims from some of the interested parties that the evidence linking cigarette smoking to lung cancer is ``only statistical'' and that harm has not been ``proved.'' This is a common form of argument in such matters of public policy.
Situations in which such controversy exists are usually difficult to deal with, partly because the observable effects may appear only in terms of probabilities, and also because of long delays in the appearance of the effects.
In such cases the concept of proof must be modified.
It is actually replaced by the concept of \textit{correlation}.
Correlation studies give results, phrased in terms of probabilities, that differ in character from the clear-cut cause-and-effect relationships with which we are familiar in other experiments.
Nevertheless, they can be equally valid for identifying the factors that influence systems.
The concept of correlation receives further consideration in Section {ref}`sec6_14`.

\section*{Problems}\label{sec5_8}
\addcontentsline{toc}{section}{\protect\numberline{}Problems}
1. A scientist claims that the terminal velocity of fall of a parachutist is dependent on only the mass of the parachutist and the acceleration due to gravity.
Is it reasonable setting up an experiment to check this suggestion?
2. The range of a projectile fired with velocity `v` at angle `\alpha` to the horizontal may depend on its mass, the velocity, the angle, and the gravitational acceleration.
Find the form of the function.
3. The pressure inside a soap bubble is known to depend on the surface tension of the material and the radius of the bubble.
What is the nature of the dependence?
4. The period of a torsion pendulum is a function of the rigidity constant (torque/unit angular deflection) of the support and the moment of inertia of the oscillating body.
What is the form of the function?
5. The deflection of a beam of circular cross section supported at the ends and loaded in the middle depends on the loading force, the length between the supports, the radius of the beam, and Young's modulus of the material.
Deduce the nature of the dependence.
\textit{In all the following problems state the variables or combination of variables that should be plotted to check the suggested variation and state how the unknown (slope, intercept, etc.) may be found.}
1. The position of a body starting from rest and subject to a uniform acceleration is described by the function
```math
s = 0.5at^2
```
\noindent `s `and `t` are measured variables.
Determine `a`.
2. The fundamental frequency of vibration of a string is given by
```math
f=\frac{1}{2\ell}\sqrt{\frac{T}{m}}
```
\noindent `f`, `\ell`, and `T` are measured variables.
Determine `m`.
3. The velocity of outflow of an ideal fluid from a hole in the side of a tank is given by
```math
v=\sqrt{\frac{2P}{\rho}}
```
\noindent `v` and `P` are measured variables.
Determine `\rho`.
4. A conical pendulum has a period given by
```math
T = 2\pi\sqrt{\frac{\ell \cos\alpha}{g}}
```
\noindent `T` and `\alpha`, are measured variables,`\ell` is fixed and known.
Determine `g`.
5. The deflection of a cantilever beam is expressed by
```math
d=\frac{4W\ell^3}{Yab^3}
```
\noindent `d`, `W`, and `\ell` are measured variables, `a` and `b` are fixed and known.
Determine
`Y`.
6. The capillary rise of a fluid in a tube is given by
```math
h = \frac{2\sigma}{\rho gR}
```
\noindent `h` and `R` are measured variables, `\rho` and `g` are fixed and known.
Determine `\sigma`.
7. The gas law for an ideal gas is
```math
pv= RT
```
\noindent `p` and `T` are measured variables, `v` is fixed and known.
Determine `R`.
8. The Doppler shift of frequency for a moving source is given by
```math
f = f_o\frac{\nu}{\nu-\nu_o}
```
\noindent `f` and `\nu_o` are measured variables, `f_o` is fixed and known.
Determine `\nu`.
9. The linear expansion of a solid is described by
```math
\ell=\ell_o\left(1+\alpha\cdot\Delta T\right)
```
\noindent `\ell` and `\Delta T` are measured variables, `\ell_o` is constant but unknown.
Determine
`\alpha`.
10. The refraction equation is
```math
n_1\sin\theta_1 =n_2 \sin\theta_2
```
\noindent`\theta_1` and `\theta_2` are measured variables, `n_1` is constant and known.
Determine
`n_2`.
11. The thin-lens (or mirror) equation can be written
```math
\frac{1}{f} = \frac{1}{s} + \frac{1}{s'}
```
\noindent `s` and `s'` are measured variables.
Determine `f`.
There are two ways of plotting this function.
Which is better?
12. The resonant frequency of a parallel `L-C` circuit is given by
```math
\omega = \frac{1}{\sqrt{LC}}
```
\noindent `\omega` and `C` are measured variables.
Determine `L`.
13. The force between electrostatic charges is described
```math
F = \frac{1}{4\pi\epsilon_o}\frac{q_1q_2}{r^2}
```
\noindent `F` and `r` are measured variables, `q_1` and `q_2` are fixed and known.
How do you check the form of the function?
14. The force between adjacent current-carrying conductors is described by
```math
F=\frac{\mu_o}{4\pi}\frac{i_1i_2\ell^2}{r^2}
```
\noindent `F`, `i_1`, `i_2`, and `r` are measured variables. `\mu_o` and `\ell` are constant.
How do you check the form of the function?
15. The discharge of a capacitor is described by
```math
Q=Q_o e^{-t/RC}
```
\noindent `Q` and `t` are measured variables. `R` is fixed and known.
Determine `C`.
16. The impedance of a series `R-C` circuit is given by
```math
Z = \sqrt{R^2+\frac{1}{\omega^2C^2}}
```
\noindent `Z` and `\omega` are measured variables.
Determine `R` and `C`.
17. The relativistic variation of mass with velocity is
```math
m=\frac{m_o}{\sqrt{1-\frac{v^2}{c^2}}}
```
\noindent `m` and `v` are measured variables.
Determine `m_o` and `c`.
18. The wavelengths of the lines in the Balmer series of the hydrogen spectrum are given by
```math
\frac{1}{\lambda} = R\left(\frac{1}{4}-\frac{1}{n^2}\right)
```
\noindent `\lambda` and `n` are measured variables.
Determine `R`.
