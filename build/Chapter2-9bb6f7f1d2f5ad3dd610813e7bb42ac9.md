# Measurement and Uncertainty\label{ch2}
## Basic Nature of Measuring Process\label{sec2_1}
Measurement is the process of quantifying experience of the external world.
The nineteenth-century Scottish scientist, Lord Kelvin, once said that ``when you can measure what you are speaking about and express it in numbers, you know something about it; but, when you cannot measure it, when you cannot express it in numbers, your knowledge is of a meager and unsatisfactory kind; it may be the beginning of knowledge, but you have scarcely in your thoughts advanced to the stage of science.'' Although this may be a slight overstatement, it remains true that measurements constitute one of the indispensable ingredients of experimenting, We cannot reach a satisfactory level of competence in experimenting without knowledge of the nature of measurement and the significance of statements about measurements.

It is obvious that the quantifying process (almost invariably involves comparison with some reference quantity (how many paces wide is my backyard?
It is equally obvious that the good order of society requires extensive agreement about the choice of these reference quantities.
Such measurement standards, defined by legislation and subject to international agreement, are extensive and important No one seriously interested in measurement can ignore defining and realizing such standards in his or her area of work.
A discussion of this important topic here would distract us from our standards without further mention (except reference to the texts listed in the Bibliography), and take up the study of measuring processes.

We start at the most basic level with an apparently simple measurement and use it to find out what kind of process is involved and what kind of statement can be made about its outcome.
If I give someone my three-ring binder containing this text with the request to measure its length with a meter stick, the answer is absolutely invariable: The length of the notebook is 29.5 cm, but that answer must make us wonder: Are we really being asked to believe that the length of the book is exactly 29.50000000 ... cm?
Surely not; such a claim is clearly beyond the bounds of credibility, So how are we to interpret the answer?
A moment's thought in the presence of the notebook and a meter stick makes us realize that, far from determining the ``right'' or ``exact'' value, the only thing we can realistically do is to approach the edge of the notebook along the scale, saying to ourselves as we go: Am I sure the answer lies below 30 cm?
Below 29.9 cm?
Below 29.8 cm?
The answer to each of these questions will undoubtedly be: Yes, As we progress along the scale, however, we eventually reach a point at which we can no longer give
the same confident reply, At that point, we must stop and identify one end
of an interval that will become our measured value.
In a similar way we can approach the edge of the notebook from below, asking ourselves at each stage: Am I sure that the answer lies above 29.0 cm?
Above 29.1 cm?
And so on.
Once again, we reach a value at which we must stop, because we can no longer say with confidence that the answer lies above it.
By the combination of these two processes we identify an interval along the scale.
It is the smallest interval that, as far as we can be certain, does contain the desired value; within the interval, however, we do not know where the answer lies.
Such is the only realistic outcome of a measuring process.
We cannot look for exact answers; we must be content with measured values that take the form of intervals.
Not only does this example illustrate the essential nature of a measuring process, it also provides guidance for actually making measurements.
The process of approaching from each side separately the value we seek is a reminder of the necessity of stating the result as an interval, and it also makes it easier to identify the edges of that interval.

The final outcome of our discussion is most important.
As we make measurements and report the results, we must constantly keep in mind this fundamental and essential point-measurements are not exact, single numbers but consist of intervals, within which we are confident that our desired value lies.
The act of measuring requires us to determine both the location and width of this interval, and we do it by the careful exercise of visual judgment every time we make a measurement.
There are no simple rules for determining the size of the interval; that depends on many factors in the measuring process, the type of measurement, the fineness of the scale, our visual acuity, the lighting conditions--all play a part in determining the width of the measurement interval.
The width, therefore, must be determined
explicitly each time a measurement is made.
For example, it is a common error to believe that, when a measurement is made using a divided scale, the ``reading error'' is automatically one-half of the finest scale division.
This is an erroneous oversimplification.
A finely divided scale used to measure an object with ill-defined edges can give a measurement interval as large as several of the finest scale divisions.
A well-defined object and good viewing conditions, on the other hand, may permit the identification of a measurement interval well within the finest scale division.
Every situation must be assessed individually.

## Digital Display and Rounding Off\label{sec2_2}
Other aspects may confuse the issue.
Consider, for example, a piece of equipment that gives a digital readout.
If a digital voltmeter shows that a certain potential difference is 15.4 V, does that readout imply that the value is
15.40000 ... exactly?
Clearly not, but what does it mean?
That depends on the circumstances.
If the instrument is made in such a way that it reads 15.4 V because the actual value is closer to 15.4 than it is to 15.3 or 15.5, then the meaning is: This reading lies between 15.35 V and 15.45 V.
On the other hand, a digital clock may be made in such a way that it changes its indication from 09.00 to 09.01 at the time of 09.01.
When we see it reading 09.00, we know that the time lies between 09.00 and 09.01, a slightly different interpretation from that appropriate to the digital voltmeter.
Again, each situation must be judged by itself.

These two examples of digital display illustrate a more general concept -- the inaccuracy inherent in the process of rounding off.
Even without the uncertainty that arises from limited ability to make measurements, the mere statement of a numerical quantity can contain uncertainty.
Consider the statement
```math
\pi=3.14
```
We all know that this is not so because we can remember some of the numbers that follow: 3.14159... and so on.
So what can we mean by quoting it as 3.14?
Presumably, we mean only that it has a value closer to 3.14 than it does to 3.13 or 3.15.
Our statement, therefore, can be translated to read -- it lies between 3.135 and 3.145.
This range of possibility represents what is sometimes known as a \textit{rounding-off error}.
The effect of such errors can be small and unimportant, or they can become significant.
In a long calculation, there is a chance that rounding-off errors either can accumulate, or they can be important in other ways.
For example, the calculation may require us to
find the difference between two large calculated values.
If these two calculated values are close together, the result that we need may be greatly affected by premature rounding off.
Because calculators make accurate calculation so easy, it is always advisable to carry the calculation through more figures than one might initially think would be necessary.
We can always do appropriate
rounding off at the end of the calculation.

A similar rounding-off error can appear in statements about measurement.
We sometimes hear that someone has made a measurement on a scale that was ``read to the nearest millimeter'' or some such phrase.
This is not a very good way of reporting a measurement because it obscures the actual
value of the measurement interval.
When we encounter such statements, we can only assume that the quoted scale division represents some kind of minimum value for the size of the measurement interval.

## Absolute and Relative Uncertainty\label{sec2_3}
Whatever the means by which we make a measurement, the final outcome should be the interval that best represents the range inside which the desired value lies.
In the example we used first, the experimenter might be able to state with confidence nothing more than that, as a consequence of a certain measuring process, the length of the notebook lay between `29.4` and `29.6` cm.
This is a perfectly satisfactory and accepted way to quote the result.
Although such a statement corresponds with the reality of the measuring process, it is frequently desirable to \textit{rephrase} the quoted value.
Take the interval `29.4` to `29.6` cm and \textit{rename} it `29.5 \pm 0.1` cm.
Although this expression is no more than a renamed statement of the original interval, the new form does offer
certain advantages.
It gives us a central value, `29.5` cm, which can be used in further calculations.
It also gives us a value, `\pm 0.1` cm, that we call the \textbf{uncertainty} of the measurement.
First, the magnitude of the uncertainty enables us to judge the quality of the measuring process.
Second, we can use this numerical measure of the uncertainty in continued calculations on uncertainties.
One disadvantage of this mode of expression is the return to a central value, `29.5` cm.
Unless we remember clearly that only the complete quantity, `29.5 \pm 0.1` cm, serves as an adequate statement of the answer, we may become sloppy in making and reporting measurements and may forget the essential presence of the uncertainty.
It should be an invariable practice to associate an uncertainty value with a reading, both at the time of the measurement and subsequently, whenever the value is quoted or used in further calculation.

Because the figure. `\pm 0.1` cm represents the actual amount, or range, by which the reading of `29.5` cm is uncertain, it is often called the \textbf{absolute uncertainty}\index{absolute uncertainty} of the measurement, and we consistently use this terminology.
For the purpose of perceiving the significance of the uncertainty, however, it is frequently convenient to extend the definition of uncertainty.
How significant
is an uncertainty of `\pm 0.1` cm?
When we measure the length of a notebook, it is significant to a certain extent.
When we measure the distance between two cities, an uncertainty of `\pm 0.1` cm surely is completely insignificant.
At the other end of the scale, however, if we measure the size of a microscopic bacterium, an uncertainty of `\pm 0.1` cm clearly makes the measurement meaningless.
Obviously, the significance of a particular uncertainty value depends on the magnitude of the measurement itself.
For this reason, it is frequently desirable to compare an uncertainty figure with the actual value of the measurement.
For this purpose, we define a quantity called the \textbf{relative uncertainty} of the measurement.
It is defined by
```math
\mathrm{Relative Uncertainty} =  \frac{\textrm Absolute Uncertainty}{\textrm Measured Value}
```
In the case of our example
```math
\mathrm{Relative Uncertainty} =  \frac{\pm 0.1}{29.5} = \pm 0.003
```
This relative uncertainty is often quoted as a percentage, so that in the present case the relative uncertainty is `\pm 0.3`\
Such a quantity gives us a much better feeling for the quality of the measurement, and we often call it the \textbf{precision} of the measurement.
The absolute uncertainty has the same dimensions and units as the basic measurement (`29.5` cm is uncertain by `0.1` cm), whereas the relative uncertainty, being a ratio, has neither dimensions nor units and is a pure number.

## Systematic Errors\label{sec2_4}
The kind of uncertainty that we have been considering arises from naturally occurring limitations in the measuring process.
A different type of error can appear when something affects all the measurements of a series in an equal or a consistent way.
For example, a voltmeter or a micrometer
caliper can have a zero error, a wooden meter stick may have shrunk, a stopwatch may be running fast or slow, and so on.
These errors are termed \textbf{systematic errors}, a subclass of which are \textbf{calibration errors}\index{calibration errors}.
Because such systematic errors may not be immediately visible as one makes a measurement, it is necessary to be vigilant and remember at all times the possibility of their presence.
Instrument zeroes, for example, should automatically be checked every time an instrument is used.
Although it may be less easy to check calibration, the accuracy of electrical meters, timing devices, thermometers; and other such instruments should not be taken for granted and should be checked whenever possible.
Also, the presence on an instrument of a precise-looking, digital readout with four or five supposedly significant figures should not be taken as proof of precision and freedom from systematic error.
Most of a batch of electronic timers that our laboratory once acquired for laboratory teaching, which could supposedly measure time intervals with millisecond accuracy, turned out to have calibration errors as large as 14\
Do not be deceived; view all measuring instruments with suspicion and check instrument calibration whenever possible.

## Uncertainty in Calculated Quantities\label{sec2_5}
The preceding sections have been concerned solely with the concept of uncertainty in a single measurement.
It is rare, however, that a single measurement ends the process.
Almost invariably the result we desire is a combination of two or more measured quantities or is at least a calculated
function of a single measurement.
We might wish, for example, to calculate the cross-sectional area of a cylinder from a measurement of its diameter, or to calculate its volume from measurements of both diameter and length.
The various measurements will sometimes be of different types, as in a calculation of `g` from values of the length and period of a pendulum.
In all such cases the presence of uncertainty in the basic measurements obviously entails the presence of uncertainty in the final computed value.
It is this final uncertainty that we now wish to calculate.
For the purposes of this section we assume that our uncertainties have the character of ranges or intervals within which we are ``almost certain'' that our answer lies.
For the computed values we calculate intervals within
which we again wish to be ``almost certain'' that our answer lies.
That means that we must do our calculation for the ``worst case'' of combined uncertainties in which the deviations in the various measured quantities happened to occur in such directions as to reinforce each other.
This is perhaps a pessimistic assumption, and we see later in Chapter 3 how the probabilities that are associated with various error combinations enable us to make a more realistic and less pessimistic estimate.
For the moment, assume that we wish to calculate from the uncertainties in the primary values the maximum range of possibility for the computed answer.

## Uncertainty in Functions of One Variable Only\label{sec2_6}
Consider a measured quantity `x_o` with an uncertainty `\pm \delta x` (where we are using finite differences such as `\delta x` to represent absolute uncertainties in the corresponding variable `x`, etc.), and consider a computed result `z` to be some function of the variable `x`.
Let
```math
z = f(x)
```
The function `f` enables us to calculate the required value `z_o` from a measured value `x_o`.
 Moreover, the possibility that `x` can range from `x_o-\delta x` to `x_o+\delta x` implies a range of possible values of `z` that range from `z_o-\delta z` to `z_o-\delta z`, where `\delta z` is the value of the absolute uncertainty in `z`.
We now wish to calculate the value of `\delta z`.
The situation is illustrated graphically in Figure {ref}`Fig2_1`, in which, for a given `f(x)`, we can see how the measured value `x_o` gives rise to the computed result `z_o`, and how the range `\pm\delta x` about `x_o` produces a corresponding range `\pm\delta z` about `z_o` .

Before considering general methods of evaluating `\delta z` It is instructive to see how finite perturbations are propagated in simple functions.
Consider, for example, the function
```math
z=x^2
```
```{figure} figures/ch2/Fig2_1.png
:Propagation of uncertainty from one variable to another.
:Fig2_1
```

If `x` can range between `x_o-\delta x` and `x_o+\delta x`, then `z` can range between `z_o-\delta z` and `z_o+\delta z`, where
\begin{equation*}
    \begin{split}
        z_o\pm\delta z & = (x_o \pm \delta x)^2


        & = x_o^2 \pm 2x_o\delta x +\left(\delta x\right)^2
    \end{split}
\end{equation*}
We can ignore `(\delta x)^2`, since `\delta x` is assumed to be small in comparison with `x_o`, and equate `z_o` to `x_o^2`, giving for the value of `\delta z`
```math
\delta z = 2xo_\delta x
```
This can more conveniently be expressed in terms of the relative uncertainty
```math
\frac{\delta z}{z_o}=\frac{2x_o\delta x}{x_o^2}=2\frac{\delta x}{x_o}
```
Thus, the relative uncertainty of the computed result is twice that of the initial measurement.

Although it is helpful to bear in mind the nature of propagated uncertainty, as illustrated by the use of finite differences, considerable simplification of the formulation can be achieved using differential calculus.

## General Method for Uncertainty in Functions of a Single Variable\label{sec2_7}
The finite differences `\delta z` and `\delta x` that were used in the preceding section could be regarded as components of the derivative `dz/dx`.
We can therefore obtain our value of `\delta z` by first using standard techniques to obtain `dz/dx` in the form
```math
\frac{dz}{dx}=\frac{d\left(f\left(x\right)\right)}{dx}
```
and then writing
```{math}
\label{eq2_1}
    \delta z =\frac{d\left(f\left(x\right)\right)}{dx}\delta x

```
This is a relatively simple procedure, and it works well in cases for which the elementary, finite-difference approach would lead to algebraic complexity.
If, for example we have to deal with the function
```math
z=\frac{x}{x^2+1}
```
then
\begin{align*}
    \frac{dz}{dx} & = \frac{x^2+1-x\times 2x}{\left(x^2+1\right)^2} 


                  & = \frac{1-x^2}{\left(x^2+1\right)^2}
\end{align*}
and
```math
\delta z = \frac{1-x^2}{\left(x^2+1\right)^2}\delta x
```
This calculation would have been very awkward if any other approach had been used.
Furthermore, it gives `\delta z` generally as a function of `x` and `\delta x`; any particular desired value can be obtained by setting `x = x_o` We now use this technique to evaluate uncertainties for some common functions.

\subsection**{Powers}
Consider the function
```math
z=x^n
```
Differentiating and replacing the derivative by finite differences gives us
\begin{align*}
    \frac{dz}{dx} & = nx^{n-1}         


    \delta z      & = nx^{n-1}\delta x
\end{align*}
The significance of this result becomes a little more obvious when expressed in terms of the relative uncertainty.
Thus,
```math
\frac{\delta z}{z} = n\frac{\delta x}{x}
```
Thus, when evaluating powers of a measured quantity, we must compute the uncertainty in the final answer using the relative uncertainty of the measured quantity.
The relative uncertainty in the final answer is the relative uncertainty of the basic quantity multiplied by the power involved.
This method is valid for either powers or roots, so that precision diminishes as a quantity is raised to powers and improves on taking roots.
This situation must be carefully watched in an experiment in which powers are involved.
The higher the power, the greater is the need for good initial precision.

\subsection*{Trigonometric Functions}
We give only one example, because all the others can be treated in similar ways.
Consider
```math
z=\sin x
```
Here
```math
\frac{dz}{dx}=\cos x
```
and
```math
\delta z = \left(\cos x\right)\delta x
```
This is one case where the elementary method of inserting `x_o\pm\delta x` in the function shows the result more clearly.
We obtain
\begin{align}
    z_o\pm \delta z & = \sin\left(x_o\pm\delta x\right)\nonumber             


                    & = \sin x_o\cos\delta x\pm\cos x_o\sin\delta x\nonumber
\end{align}
Since `z_o = \sin x_o` and `\cos\delta x\approx 1`, this becomes
```math
\delta z = \cos x_o\sin\delta x
```
This result makes it clear that the `\delta x` in the original expression was really an approximate form of `\sin \delta x`.
Only in the case of very large uncertainty would this difference be significant, but it is best to be aware of the situation.
For one thing, it allows us to understand that, when we use that original expression, we must express the uncertainty in angle, `\delta x`, in \textit{radian} measure, because only then can we replace `\sin \delta x` by `\delta x` itself.
Such uncertainty calculations using trigonometric functions normally have straightforward application when
dealing with apparatus such as spectrometers.

\subsection*{Logarithmic and Exponential Functions}
Consider the function
```math
z=\log x
```
Here
```math
\frac{dz}{dx} = \frac{1}{x}
```
and
```math
\delta z = \frac{1}{x}\delta x
```
and the relative uncertainty can be calculated as usual.

If
```math
z=e^x
```
then
```math
\frac{dz}{dx} = e^x
```
and
```math
\delta z = e^x\delta x
```
This is an important case, because exponential functions occur frequently in science and engineering.
These functions can become very sensitive to the exponent when it takes values much over unity, and the uncertainty `\delta z` may become very large.
As stated earlier, the method can be easily applied to any function not listed above by evaluating the appropriate derivative and using Equation {ref}`eq2_1`.

## Uncertainty in Functions of Two or More Variables\label{sec2_8}
If the result is to be computed from two or more measured quantities. `x, y`, and so on, the uncertainty in the result can, as was mentioned in Section {ref}`sec2_5`, be regarded in two ways.
We could be as pessimistic as possible and suppose that the actual deviations of `x` and `y` happen to combine in such a way as to drive the value of `z` as far as possible from the central value.
In this way, we would calculate the value for oz that gives the extreme width of the range of possible `z` values.
On the other hand, we could argue that it is more probable for the uncertainties in the basic measurements to combine in a less extreme way, some making positive contributions to `\delta z` and some negative, so that the resulting `\delta z` would be smaller than for the pessimistic assumption.
This argument is valid, and later we deal with the question of probable uncertainty in computed quantities.
For the moment, however, we calculate the value of `\delta z` that represents the widest range of possibility for `z`.
Such an approach, If pessimistic, is certainly safe, because, if `\delta x`, `\delta y`, and so forth, represent limits within which we are ``almost certain'' the actual values lie, then the calculated `\delta z` will give those limits within which we are equally certain that the actual value of `z` lies.

The most instructive initial approach uses the elementary substitution method, and we use this for the first two functions.

\subsection*{Sum of Two or More Variables}
Consider the function of two variables
```math
z=x+y
```
The uncertainty in `z` will be obtained from
```math
z_o\pm\delta z = \left(x_o\pm\delta x\right) + \left(y_o\pm\delta y\right)
```
and the maximum value of `\delta z` is obtained by choosing similar signs throughout the right-hand side of the expression.
Thus,
```math
\delta z = \delta x + \delta y
```
As might be expected, the uncertainty in the sum is just the sum of the individual uncertainties.
This can be expressed in terms of the relative uncertainty
```math
\frac{\delta z}{z} = \frac{\delta x + \delta y}{x+y}
```
but no increased clarification is achieved.
If the quantity `z` contains the sum of more than two variables, the expression for the uncertainty in `z` can obviously be extended as necessary.

\subsection*{Difference of Two Variables}
Consider a quantity that must be calculated as the difference between two
measured values.
Let
```math
z=x-y
```
As in the preceding case, `\delta z` is obtained from
```math
z_o\pm\delta z = \left(x_o\pm\delta x\right) - \left(y_o\pm\delta y\right)
```
Here, however, we can obtain the maximum value of `\delta z` by choosing the \textit{negative} sign for `\delta y`, giving again,
```math
\delta z = \delta x + \delta y
```
We can see from this equation that, when `x_o` and `y_o` are close together and the value of `x - y` is small, the relative uncertainty can rise to very large values.
This is at best an unsatisfactory situation, and the precision can be low enough to destroy the value of the measurement.
The condition is particularly hazardous because it can arise unnoticed.
It is perfectly obvious that, if it were possible to avoid it, no one would attempt to measure the length of my notebook by measuring the distance of each edge from a point a mile away and then subtracting the two lengths.
However, a desired result can be obtained by subtraction of two measurements made separately (two thermometers, clocks, etc.), and the character of the measurement as a difference may not be strikingly obvious.
Consequently, treat all measurements involving differences with the greatest caution.
Clearly, the way to avoid the difficulty is to measure the difference directly, rather than obtaining it by subtraction between two measured quantities.
For example, if you have an apparatus within which two points are at potentials above ground of `V_1 = 1500` V and `V_2 = 1510` V, respectively, and the required quantity is `V_2 - V_1`, only a voltmeter of very high quality would permit the values
of `V_1` and `V_2` to be measured with the exactness required to achieve even 10\
On the other hand, an ordinary 10 V table voltmeter, connected between the two points and measuring `V_2 - V_1` directly, immediately gives the desired result with 2\

## General Method for Uncertainty in Functions of Two or More Variables\label{sec2_9}
The last two examples, treated by the elementary method, suggest that the differential calculus may offer considerable simplification of the treatment.
It is clear that if `z` is a function of the two variables `x` and `y`,
```math
z = f(x, y)
```
the appropriate quantity for calculating oz is the total differential `dz`.
This is given by
```{math}
\label{eq2_2}
    dz = \frac{\partial f}{\partial x}dx + \frac{\partial f}{\partial y}dy

```
We treat this differential as a finite difference `\delta z` that can be calculated from the uncertainties `\delta x` and `\delta y`.
Thus,
```math
\delta z = \frac{\partial f}{\partial x}\delta x + \frac{\partial f}{\partial y}\delta y
```
and the derivatives `\partial f/\partial x` and `\partial f/\partial y` are normally evaluated for the values, `x_o` and `y_o`, at which `\delta z` is required.
We may find that, depending on the function `f` the sign of `\partial f/\partial x` or `\partial f/\partial y` turns out to be negative.
In this case, using our pessimistic requirement for the maximum value of `\delta z`, we choose
negative values for the appropriate `\delta x` or `\delta y`, obtaining thereby a wholly positive contribution to the sum.

\subsection*{Product of Two or More Variables}
Suppose
```math
z=xy
```
To use Equation {ref}`eq2_2` we need the values of `\partial z/\partial x` and `\partial z/\partial y`.
They are
```math
\frac{\partial z}{\partial x}=y \textrm{  and  } \frac{\partial z}{\partial y}=x
```
Thus, the value of `\delta z` is given by
```math
\delta z = y\delta x + x\delta y
```
The significance of this result is more clearly seen when it is converted to the relative uncertainty
```math
\frac{\delta z}{z} = \frac{\delta x}{x} + \frac{\delta y}{y}
```
Thus, when the desired quantity is a product of two variables, its \textit{relative uncertainty} is the sum of the \textit{relative uncertainties} of the components.
Notice the contrast with the result for uncertainty in the case of two added variables, where we must combine the uncertainties using the \textit{absolute} uncertainties.
The most general case of a compound function, very commonly found in physics, involves an algebraic product or quotient that has components raised to powers.
Consider the function
```math
z=x^ay^b
```
where `a` and `b` may be positive or negative, integral or fractional.
This formulation is greatly simplified by taking logarithms of both sides before differentiating.
Thus,
```math
\log z = a\log x + b\log y
```
whence, differentiating implicitly,
```math
\frac{dz}{z} = a\frac{dx}{x}+b\frac{dy}{y}
```
As usual, we take the differentials to be finite differences and obtain
```math
\frac{\delta z}{z} = a\frac{\delta x}{x}+b\frac{\delta y}{y}
```
If the original expression for `z` contains more than two variables, we can simply extend the result for `\delta z` by adding terms as appropriate.
 s process gives the relative uncertainty directly, which is frequently convenient: If the absolute uncertainty `\delta z` is required, it can be evaluated simply by multiplying the relative uncertainty by the computed value `z_o`, which is normally available.
This form of implicit differentiation still offers the simplest procedure even
when `z` itself is raised to some power.
For example, if the equation reads
```math
z^2=xy
```
it is unnecessary to rewrite it
```math
z=x^{1/2}y^{1/2}
```
and work from there, because, by taking logs
```math
2\log z = \log x +\log y
```
whence
```math
2\frac{\delta z}{z} = \frac{\delta x}{x}+\frac{\delta y}{y}
```
giving `\delta z` as required.

\subsection*{Quotients}
Quotients can be treated as products in which some of the powers are negative.
As before, the maximum value of `\delta z`  is obtained by neglecting negative
signs in the differential and combining all the terms additively.
If a function other than those already listed is encountered, some kind
of differentiation usually works.
It is frequently convenient to differentiate an
equation implicitly, thereby avoiding the requirement to calculate the unknown
quantity explicitly as a function of the other variables.
For example,
consider the thin-lens equation.
If we had made measurements of the object
distance `s` and the image distance `s'` for a thin lens with the intention of calculating a value for its focal length, `f`, the equation we would use is
```math
\frac{1}{f} = \frac{1}{s}+\frac{1}{s'}
```
To obtain the uncertainty in `f`, we can differentiate the equation implicitly to obtain
```math
-\frac{df}{f^2} = \frac{ds}{s^2}+\frac{ds'}{s'^2}
```
It is now possible to calculate `df / f` directly and more easily than by writing `f` explicitly as a function of `s` and `s'`, and differentiating.
In this way we can prepare a formula for the uncertainty into which all the unknowns can be inserted directly.
Make sure that appropriate signs are used so that all contributions to the uncertainty add positively to give outer limits of possibility for the answer.

If the function is so big and complicated that we cannot obtain a value for `\delta z` in general, we can always take the measured values, `x_o`, `y_o`, and so on, and work out zoo We can then work out two different answers, one using the actual numerical values of `x_o + \delta x`, `y_o + \delta y` (or `y_o - \delta y` if appropriate), and so forth to give one of the outer values of `z`, and the other using `x_o-\delta x`, and so on.
These two values correspond to the outer limits on `z`, and we know the value of `\delta z`.

## Compensating Errors\label{sec2_10}\index{compensating errors}
A special situation can appear when compound variables are involved.
Consider, for example, the well-known relation for the angle of minimum deviation `_m` for a prism of refractive index `n` and vertical angle `A`:
```math
n=\frac{\sin\left(\frac{1}{2}\left(A+D_m\right)\right)}{\sin\left(\frac{A}{2}\right)}
```
If `A` and `D_m` are measured variables with uncertainties `\delta A` and `\delta D_m`, the
quantity `n` will be the required answer, with an uncertainty `\delta_m`.
It would be fallacious, however, to calculate the uncertainty in `A + D_m`, then in `\sin\left(\frac{1}{2}\left(A+D_m\right)\right)`, and combine that with the uncertainty in `\sin\left(\frac{A}{2}\right)`, as if the function were a quotient of two independent variables.
This can be seen by
thinking of the effect on `n` of an increase in `A`.
Both `\sin\left(\frac{1}{2}\left(A+D_m\right)\right)` and `\sin\left(\frac{A}{2}\right)` increase, and the change in `n` is not correspondingly large.
The error lies in applying the methods of the preceding sections to variables, such as `A` and `A + D_m` that are not independent.
The cure is either to reduce the equation to a form in which the variables are all independent or else to go back to first
principles and use Equation {ref}`eq2_2` directly.
Cases that involve compensating errors should be watched carefully, because if they are treated incorrectly, they give rise to errors in uncertainty calculations that are hard to detect.

## Significant Figures\label{sec2_11}
Because computations tend to produce answers consisting of long strings of numbers, we must be careful to quote the final answer sensibly.
If, for example, we are given the voltage across a resistor as `15.4 \pm 0.1` volts and the current as `1.7 \pm 0.1` amps, we can calculate a value for the resistance.
The ratio `V/I` comes out on my calculator as `9.0588235` ohms.
Is this the answer?
Clearly not.
A brief calculation shows that the absolute uncertainty in the resistance is close to `0.59` ohms.
So, if the first two places of decimals in the value for the resistance are uncertain, the rest are clearly meaningless.
A statement like `R = 9.0588235 \pm 0.59` ohms is, therefore, nonsense.
We should quote our results in such a way that the answer and its uncertainty are consistent, perhaps something like `R = 9.06 \pm 0.59` ohms.
But is even this statement really valid?
Remember that the originally quoted uncertainties for `V` and `I` had the value `\pm 0.1`, containing one significant figure.
If we do not know these uncertainties any more precisely than that, we have no right to claim two significant figures for the uncertainty in `R`.
Our final, valid, and self-consistent statement is, therefore, `R = 9.1 \pm 0.6` ohms.
Only if we had a good reason
to believe that our original uncertainty was accurate to two significant figures, could we lay claim to two significant figures in the final uncertainty and a correspondingly more precisely quoted value for `R`.
In general terms, we must make sure that our quoted values for uncertainty are consistent with the precision of the basic uncertainties, and that the number of quoted figures in the final answer is consistent with the uncertainty of that final answer.
We must avoid statements like `z= 1.234567\pm0.1` or `z= 1.2 \pm 0.000001`.

\section*{Problems}\label{sec2_12}
\addcontentsline{toc}{section}{\protect\numberline{}Problems}
1. I use my meter stick to measure the length of my desk.
I am sure that the length is not less than 142.3 cm and not more than 142.6 cm.
State this measurement as a central value `\pm` uncertainty.
What is the relative uncertainty of the measurement?
2. I read a needle-and-scale voltmeter and ammeter and assess the range of uncertainty visually.
I am sure, the ammeter reading lies between 1.24 and 1.25 A and the voltmeter reading between 3.2 and 3.4 V.
Express each reading as a central value `\pm` uncertainty and evaluate the relative uncertainty of each measurement.
3. My digital watch gives a time reading as 09:46.
    What is the absolute uncertainty of the measurement?
4. If I can read a meter stick with absolute uncertainty `\pm 1` mm, what is the shortest distance that I can measure if the relative uncertainty is not to exceed (a) 10\
5. I use a thermometer graduated in fifths of a degree Celsius to measure outside air temperature.
Measured to the nearest fifth degree, yesterday's temperature was 22.40 Celsius and today's is 24.80 Celsius.
What is the relative uncertainty in the temperature difference between yesterday and today?
6. The clock in the lab has a seconds hand that moves in one-second steps.
I use it to measure a certain time interval.
At the beginning of the interval it reads 09:15:22 (hours:minutes:seconds), and at the end it reads 09:18:16.
What is the relative uncertainty of the measured time interval?
7. For the desk mentioned in Problem 1, I measure the width, and I am sure the measurement lies between 78.2 cm and 78.4 cm.
What is the absolute uncertainty of the calculated area of the desktop?
8. In measuring the resistance of a resistor, the voltmeter reading was `15.2 \pm 0.2` V and the ammeter reading was `2.6 \pm 0.1` A.
What is the absolute uncertainty of the resistance calculated using the equation `R = V / I`?
9. A simple pendulum is used to measure the acceleration of gravity using
          ```math
T= 2\pi\sqrt{\frac{\ell}{g}}
```
          The period `T` was measured to be `1.24 \pm 0.02` s and the length to be `0.381 \pm 0.002` m.
What is the resulting value for `g` with its absolute and relative uncertainty?
10. An experiment to measure the density, `d`, of a cylindrical object uses the equation
          ```math
d=\frac{m}{\pi r^2\ell}
```
          where
          \begin{center}
              `m` = mass = `0.029 \pm 0.005` kg


              `r` = radius = `8.2 \pm 0.1` mm


              `\ell` = length = `15.4 \pm 0.1` mm
          \end{center}
          What is the absolute uncertainty of the calculated value of the density?
11. The focal length, `f`, of a thin lens is to be measured using the equation
          ```math
\frac{1}{f}=\frac{1}{s}+\frac{1}{s'}
```
          where
          \begin{center}
              `s` = object distance = `0.154 \pm 0.002` m


              `s'` = image distance = `0.382 \pm 0.002` m
          \end{center}
          What is the calculated value for focal length, its absolute uncertainty, and its relative uncertainty?
12. A diffraction grating is used to measure the wavelength of light using the equation
          ```math
d\sin\theta = \lambda
```
          The value of `\theta` is measured to be `13^{\circ} 34' \pm 2'`.
          Assuming that the value
          of `d` is `1420 \times 10^{-9}` m and that its uncertainty can be ignored, what are the absolute and relative uncertainties in the value of `\lambda`?
13. A value is quoted as `14.253 \pm 0.1`.
    Rewrite it with the appropriate number of significant figures.
If the value is quoted as `14.253 \pm 0.15`, how should it be written?
14. A value is quoted as `6.74914 \pm 0.5`\
    State it as a value `\pm` absolute uncertainty,
          both with the appropriate number of significant figures.
